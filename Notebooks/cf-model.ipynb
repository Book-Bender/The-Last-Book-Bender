{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "339e46d3-890d-4e07-8488-dafeea1f4721",
   "metadata": {},
   "source": [
    "# CF book rec for user with context\n",
    "\n",
    "This notebook demonstrates predicting rating of books for a user with records using goodreads-10k.\n",
    "\n",
    "We have seen that for UBCF (user-based collaborative filtering), adjusted cosine similarity as a model for has good CV score (for RMSE, MAE).\n",
    "\n",
    "This notebook implements model to generate top book ids for users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8114a7c1-4fa8-4998-9787-4c2f9cef49c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zebalgebra/School/DVA/The-Last-Book-Bender/Notebooks\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "!readlink -f . # this reads filepath to the directory holding this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9a28ce4-e53c-4d7f-9a0f-a1f6945e7a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your path to data directory here\n",
    "fp = \"/home/zebalgebra/School/DVA/The-Last-Book-Bender/Data/Raw/\"\n",
    "fname = \"ratings_for_cf.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86406d4-72a3-4ef2-8d43-23c9197608b6",
   "metadata": {},
   "source": [
    "if you don't have the file `ratings_for_cf.npz`, execute this block to generate one; this reads raw csv, center each rating, and shift a little to give more useful recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65f3aa0c-fd8d-4d43-8900-1c51c97dd7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.41 s, sys: 1.33 s, total: 5.73 s\n",
      "Wall time: 4.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "df = pd.read_csv(fp + \"ratings.csv\")\n",
    "\n",
    "# this shifts ratings by mean\n",
    "mean = df.groupby(\"user_id\").agg({\"rating\": \"mean\"}).rename(columns={\"rating\": \"mean\"})\n",
    "df = df.merge(mean, on=\"user_id\")\n",
    "df[\"rating\"] = df[\"rating\"] - df[\"mean\"] + 10 ** (-8)\n",
    "\n",
    "# generate and save csc matrix\n",
    "mat = sp.sparse.csc_matrix(\n",
    "    (\n",
    "        np.array(df[\"rating\"]),\n",
    "        (\n",
    "            np.array(df[\"book_id\"]),\n",
    "            np.array(df[\"user_id\"])\n",
    "        )\n",
    "    )\n",
    ")\n",
    "with open(fp + \"ratings_for_cf.npz\", \"wb\") as f:\n",
    "    sp.sparse.save_npz(f, mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d427c-fd9b-477e-95df-b6e0e450ae22",
   "metadata": {},
   "source": [
    "## Demo on predicting ratings\n",
    "Execute the following block to initialize model.\n",
    "\n",
    "Every method prefixed by _ are intended as internal methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce00e48-e714-4b3d-b835-1d835cc5bc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cf_model:\n",
    "    \n",
    "    def __init__(self, fp, fname):\n",
    "        \"\"\"\n",
    "        assumes ratings data has users ratings shifted by means\n",
    "        here mat has rows the books, columns the users.\n",
    "        \"\"\"\n",
    "        self.mat = sp.sparse.load_npz(fp + fname)\n",
    "        self.norms = np.sqrt(np.array(self.mat.power(2).sum(axis=0))).flatten()\n",
    "        self.n_books, self.n_users = self.mat.shape\n",
    "        \n",
    "    def _context_to_vec(self, context):\n",
    "        \"\"\"\n",
    "        utility. for transforming context into np array or scipy csc.\n",
    "        \"\"\"\n",
    "        if type(context) not in [\n",
    "            sp.sparse._csc.csc_matrix,\n",
    "            sp.sparse._csr.csr_matrix,\n",
    "            sp.sparse._coo.coo_matrix,\n",
    "            np.ndarray,\n",
    "            list,\n",
    "            tuple,\n",
    "            dict\n",
    "        ]:\n",
    "            raise NotImplementedError(\"type not supported.\")\n",
    "        if type(context) in [sp.sparse._csr.csr_matrix, sp.sparse._coo.coo_matrix]:\n",
    "            context = context.tocsc()\n",
    "        if type(context) is np.ndarray:\n",
    "            context = sp.sparse.csc_matrix(context)\n",
    "        if type(context) is sp.sparse._csc.csc_matrix:\n",
    "            if context.shape[0] == 1:\n",
    "                context = context.transpose().tocsc()\n",
    "            return context\n",
    "        if len(context) == 0:\n",
    "            vec = sp.sparse.csc_matrix(0)\n",
    "            vec.resize((self.n_books, 1))\n",
    "            return vec\n",
    "        if type(context) is dict: # assumes the form {book_id: rating}\n",
    "            context = list(context.items())\n",
    "        n = len(context)\n",
    "        return sp.sparse.csc_matrix(\n",
    "            (\n",
    "                np.array([t[1] for t in context]), # data\n",
    "                (\n",
    "                    np.array([t[0] for t in context]).astype(int),\n",
    "                    np.zeros(n).astype(int) # columns\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def _get_mean(self, context_vec):\n",
    "        \"\"\"\n",
    "        utility. assumes context_vec is scipy sparse csc matrix or np array\n",
    "        \"\"\"\n",
    "        if type(context_vec) is np.ndarray:\n",
    "            return context_vec.mean()\n",
    "        if type(context_vec) is sp.sparse._csc.csc_matrix:\n",
    "            return context_vec.data.sum() / len(context_vec.data)\n",
    "\n",
    "    def _process_context(self, context_vec):\n",
    "        \"\"\"\n",
    "        utility. assumes context_vec is scipy sparse csc matrix or np array\n",
    "        \"\"\"\n",
    "        mu = self._get_mean(context_vec)\n",
    "        if type(context_vec) is np.ndarray:\n",
    "            # center by mean\n",
    "            supp = context_vec != 0\n",
    "            context_vec[supp] = (context_vec[supp] - mu + 10 ** (-8))\n",
    "            # normalize\n",
    "            s2 = (context_vec ** 2).sum() # sum of elements squared\n",
    "            context_vec[supp] = context_vec[supp] / np.sqrt(s2)\n",
    "            return context_vec\n",
    "        if type(context_vec) is sp.sparse._csc.csc_matrix:\n",
    "            # center by mean\n",
    "            context_vec.data = (context_vec.data - mu + 10 ** (-8))\n",
    "            # normalize\n",
    "            s2 = (context_vec.data ** 2).sum()\n",
    "            context_vec.data = context_vec.data / np.sqrt(s2)\n",
    "            return context_vec\n",
    "\n",
    "    def _top_k_neighbors(self, context, k=50):\n",
    "        \"\"\"\n",
    "        get top k indices given context_vec;\n",
    "        assumes context_vec is context processed by _process_context.\n",
    "        \"\"\"\n",
    "        context_vec = self._process_context(self._context_to_vec(context))\n",
    "        if np.prod(context_vec.shape) != self.n_books: # otherwise would raise dimension mismatch\n",
    "            context_vec.resize((self.n_books, 1))\n",
    "        # the following inevitably a dense vector\n",
    "        sim_scores = (self.mat.T @ context_vec).toarray().flatten() / np.maximum(self.norms, 10 ** (-30))\n",
    "        neighbors = np.argpartition(sim_scores, -k)[-k:] # note: this returns top k; needn't be sorted for better performance\n",
    "        sim_scores = sim_scores[neighbors]\n",
    "        return neighbors, sim_scores\n",
    "\n",
    "    def _get_scores(self, context, k=50):\n",
    "        \"\"\"\n",
    "        using the approximate formula for better vectorization; use nonnormalized\n",
    "        \"\"\"\n",
    "        neighbors, sim_scores = self._top_k_neighbors(context, k=k)\n",
    "        submat = self.mat[:, neighbors].toarray() # retrieve rating records of these neighbors\n",
    "        numer = submat * sim_scores\n",
    "        denom = (submat > 0) * sim_scores\n",
    "        scores = numer.sum(axis=1) / np.maximum(\n",
    "            denom.sum(axis=1),\n",
    "            10 ** (-30)\n",
    "        )\n",
    "        return scores\n",
    "\n",
    "    def get_top_m_recs_k_neighbors(self, context, k=50, m=100):\n",
    "        \"\"\"\n",
    "        grabs top m books; will take a peak at cache to see if need recomputation\n",
    "        \"\"\"\n",
    "        scores = self._get_scores(context, k=k)\n",
    "        top_m_inds = np.argpartition(scores, -m)[-m:]\n",
    "        top_m_scores = scores[top_m_inds]\n",
    "        return sorted(zip(top_m_scores, top_m_inds))[::-1]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863f0cf8-4844-4899-9c79-3da99e6b2038",
   "metadata": {},
   "source": [
    "## Usage Demonstration\n",
    "Initialize model with the processed ratings matrix, specified by filepath to directory and filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fd52aed-1f52-40d6-be82-7be4858ed93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 236 ms, sys: 8.97 ms, total: 245 ms\n",
      "Wall time: 245 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = cf_model(fp, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d471446a-3d92-45ab-b05f-d9583a541e4e",
   "metadata": {},
   "source": [
    "You can define context as:\n",
    "1. A dictionary of book_id: value.\n",
    "2. A list or tuple of pairs (book_id, value) or [book_id, value].\n",
    "3. An numpy vector with v[book_id]=value.\n",
    "4. A scipy sparse vector.\n",
    "\n",
    "To get top recommendations, you need to specify how many neighbors to use (this is the value of `k` to pass in), how many recommendations to generate (this is the value of `m` to pass in).\n",
    "\n",
    "Say your user rated book id 1 with 1, book id 2 also with 1. You can generate book recs as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c566bfd5-ea4a-40d4-ba7b-b5842b6ef868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 ms, sys: 579 Âµs, total: 22 ms\n",
      "Wall time: 21 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2.12372248389602, 681), (2.00000001, 2157), (2.00000001, 1969)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "context_dict = {1: 1, 2: 1}\n",
    "context_t_t = ((1, 1), (2, 1))\n",
    "context_l_t = [(1, 1), (2, 1)]\n",
    "context_t_l = ([1, 1], [2, 1])\n",
    "context_l_l = [[1, 1], [2, 1]]\n",
    "context_np = np.array([0, 1, 1, 0, 0])\n",
    "context_sp_csc = sp.sparse.csc_matrix(np.array([0, 1, 1, 0, 0]))\n",
    "context_sp_csr = sp.sparse.csr_matrix(np.array([0, 1, 1, 0, 0]))\n",
    "context_sp_coo = sp.sparse.coo_matrix(np.array([0, 1, 1, 0, 0]))\n",
    "\n",
    "context = context_dict\n",
    "\n",
    "model.get_top_m_recs_k_neighbors(context, k=100, m=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4d4999-a835-40f3-9fe9-acc9a59ee47d",
   "metadata": {},
   "source": [
    "This says for example that the book with id 681 gives a difference in rating of 2.124 to the user's baseline.\n",
    "## A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
