{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a3d828-411d-4484-be65-f9cde9c172fe",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Notebook with `surprise` (demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c061063e-a0fd-4128-89bc-7c0217b3ad19",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37dcb27-90e1-41e5-802b-28f34b5eeb72",
   "metadata": {},
   "source": [
    "These lines loads the ratings and convert it to `surprise.Dataset` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eee9e1e6-d6f3-4c55-913c-ddcab04b8ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id    53424\n",
       "book_id    10000\n",
       "rating         5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset, NormalPredictor, Reader\n",
    "import pandas as pd\n",
    "ratings_df = pd.read_csv(\n",
    "    filepath_or_buffer=\"../Data/Raw/ratings.csv\",\n",
    "    dtype={\n",
    "        \"user_id\": \"Int32\",\n",
    "        \"book_id\": \"Int32\",\n",
    "        \"rating\": \"Int8\"\n",
    "    }\n",
    ")\n",
    "ratings_sdata = Dataset.load_from_df(\n",
    "    df=ratings_df,\n",
    "    reader=Reader(rating_scale=(1, 5))\n",
    ")\n",
    "ratings_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9988963-46a5-45f1-a6f3-b234892e3f49",
   "metadata": {},
   "source": [
    "We can choose a similarity metric for CF, given by the `surprise.similarities` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d75e5e90-977e-41e4-b941-30a0f895537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBasic\n",
    "sim_options = {\n",
    "    \"name\": \"cosine\", # options: cosine, msd, pearson, pearson_baseline\n",
    "    \"user_based\": False,  # False=CF on item; True=CF on user\n",
    "    \"shrinkage\": 0, # takes effect if \"name\" set to pearson_baseline, can prevent overfit\n",
    "    \"min_support\": 1, # if num of common ratings is less than this, truncates to 0, reduces user-item matrix density\n",
    "}\n",
    "algo = KNNBasic(sim_options=sim_options) # other algo options: https://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3a7989-9137-4210-8081-a7001845e8bd",
   "metadata": {},
   "source": [
    "To train, we need to convert a `surprise.Dataset` object to a `surprise.Trainset` object.\\\n",
    "Suppose we want to train on the whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11a1726d-525b-4f4e-bffc-1b01b3cd0ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_strain = ratings_sdata.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef35b700-e090-41b8-8036-0b3eacc4b544",
   "metadata": {},
   "source": [
    "Combining `algo` and `ratings_strain`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0d236add-2d10-49e9-bae9-ee60e383d121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Ellapsed time: 43.53758215904236 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "algo.fit(ratings_strain)\n",
    "print(f\"Ellapsed time: {time.time() - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9606d16c-d9fb-4770-a5ed-6dcf90e3d963",
   "metadata": {},
   "source": [
    "## Compute Predictions, Training Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f291b4-60a2-49db-a036-7dc5629af7bf",
   "metadata": {},
   "source": [
    "One can test the train loss over itself. Build first a trainset from the testset, make prediction, then plug in accuracy metrics\\\n",
    "The prediction step will take a big while if predicting over the entire training set (6 million ratings available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ffcaf135-296c-4c27-91b9-f471257807e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ellapsed time: 1157.4575111865997 seconds\n"
     ]
    }
   ],
   "source": [
    "ratings_stest = ratings_strain.build_testset()\n",
    "start_time = time.time()\n",
    "predictions = algo.test(ratings_stest)\n",
    "print(f\"Ellapsed time: {time.time() - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236fa613-cc46-4d93-bc4a-ca1cc29e253f",
   "metadata": {},
   "source": [
    "A peak to `predictions`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fae2895b-32f9-49c2-9cc1-c33be3a243f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5976479\n",
      "user: 219        item: 4338       r_ui = 4.00   est = 4.15   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 219        item: 190        r_ui = 3.00   est = 4.05   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 219        item: 4629       r_ui = 3.00   est = 4.03   {'actual_k': 40, 'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions))\n",
    "for x in predictions[12345:12348]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf9c0c3-a2ba-4943-a376-eb3ae235f655",
   "metadata": {},
   "source": [
    "where `r_ui` is true rating and `est` is estimated rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523273dd-5b5c-4a56-b4bf-85450a95fdf1",
   "metadata": {},
   "source": [
    "Training losses can be computed by `surprise.accuracy`'s functions; here the all four options are listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "943b3d30-3dc2-4ca5-a978-74471d062e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean square error: 0.7923006406161057\n",
      "Mean squared error: 0.6277403051206915\n",
      "Mean absolute error: 0.6057735404799971\n",
      "Fraction of concordant paris: 0.8216831080054721\n",
      "Ellapsed time evaluating losses: 63.667232513427734 seconds\n"
     ]
    }
   ],
   "source": [
    "from surprise.accuracy import rmse, mse, mae, fcp\n",
    "start_time = time.time()\n",
    "for n, f in [\n",
    "    (\"Root mean square error\", rmse),\n",
    "    (\"Mean squared error\", mse),\n",
    "    (\"Mean absolute error\", mae),\n",
    "    (\"Fraction of concordant paris\", fcp)\n",
    "]:\n",
    "    print(f\"{n}: {f(predictions, verbose=False)}\")\n",
    "print(f\"Ellapsed time evaluating losses: {time.time() - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a2849c-fb1b-4690-b06e-c5506dfaa9e1",
   "metadata": {},
   "source": [
    "## Query KNN (for items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e189b4c-85d3-4627-848c-8a04faf0de35",
   "metadata": {},
   "source": [
    "We trained the model with `user_based=False`, so we can try to query similar book items (may compare this to the corresponding section of the `bert` notebook). Let us look at the most similar books for the most popular ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "68306f4c-f39e-4903-aa7a-9226eb00891a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>21850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>16931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  count\n",
       "0        1  22806\n",
       "1        2  21850\n",
       "2        3  16931"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_top_3_ids_df = ratings_df\\\n",
    "                        .groupby(\"book_id\", as_index=False)\\\n",
    "                        .agg(count=(\"user_id\", \"count\"))\\\n",
    "                        .head(3)\n",
    "books_top_3_ids_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec2fe5-4fa3-4f1d-9073-be5fc3098ead",
   "metadata": {},
   "source": [
    "Book infos retrieved and joined from other dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dbe96486-46d4-46cc-b969-40a46dfef02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['Suzanne Collins']</td>\n",
       "      <td>The Hunger Games (The Hunger Games, #1)</td>\n",
       "      <td>22806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['J.K. Rowling', 'Mary GrandPré']</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n",
       "      <td>21850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>['Stephenie Meyer']</td>\n",
       "      <td>Twilight (Twilight, #1)</td>\n",
       "      <td>16931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id                            authors  \\\n",
       "0        1                ['Suzanne Collins']   \n",
       "1        2  ['J.K. Rowling', 'Mary GrandPré']   \n",
       "2        3                ['Stephenie Meyer']   \n",
       "\n",
       "                                               title  count  \n",
       "0            The Hunger Games (The Hunger Games, #1)  22806  \n",
       "1  Harry Potter and the Sorcerer's Stone (Harry P...  21850  \n",
       "2                            Twilight (Twilight, #1)  16931  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df = pd.read_csv(\n",
    "    filepath_or_buffer=\"../Data/Raw/books_enriched.csv\"\n",
    ")[[\"book_id\", \"authors\", \"title\"]]\n",
    "books_df.merge(\n",
    "    right=books_top_3_ids_df,\n",
    "    left_on=[\"book_id\"],\n",
    "    right_on=[\"book_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316e921b-d91d-449a-b442-a488a7762a0e",
   "metadata": {},
   "source": [
    "then we can call `algo.get_neighbors()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e8e3b106-62d8-441b-ae29-053cc30d12f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 57, 60], [11, 157, 246], [10, 11, 29]]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_top_3_ids = books_top_3_ids_df[\"book_id\"].to_list()\n",
    "reccomend_top_3_for_top_3 = [algo.get_neighbors(book_id, k=3) for book_id in books_top_3_ids]\n",
    "reccomend_top_3_for_top_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb4bd60-a64a-4983-89d5-672780902cde",
   "metadata": {},
   "source": [
    "Inferring reccomendations book titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "24f730c3-c273-4694-99f8-6ab60d5c1f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top three titles for The Hunger Games (The Hunger Games, #1):\n",
      "['Pride and Prejudice', 'The Secret Life of Bees', 'The Curious Incident of the Dog in the Night-Time']\n",
      "Top three titles for Harry Potter and the Sorcerer's Stone (Harry Potter, #1):\n",
      "['The Kite Runner', 'Green Eggs and Ham', 'Marked (House of Night, #1)']\n",
      "Top three titles for Twilight (Twilight, #1):\n",
      "['Pride and Prejudice', 'The Kite Runner', 'Romeo and Juliet']\n"
     ]
    }
   ],
   "source": [
    "books_id_name_dict = dict(zip(books_df.book_id, books_df.title))\n",
    "for book_id, rec_ids in zip(books_top_3_ids, reccomend_top_3_for_top_3):\n",
    "    print(f\"Top three titles for {books_id_name_dict[book_id]}:\")\n",
    "    print(f\"{[books_id_name_dict[rec_id] for rec_id in rec_ids]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11c957e-aeb7-41fd-9a97-e3b78f6a4c2c",
   "metadata": {},
   "source": [
    "Seems to be a bit irrelevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dda725-2efd-4ba5-9fae-1398f5cd7045",
   "metadata": {},
   "source": [
    "## Dump Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1154d8ad-d155-4b55-ac31-546d0f10e637",
   "metadata": {},
   "source": [
    "`surprise` provides a `dump` module for dumping and loading models.\\\n",
    "For our model size, dumping would take up a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e4e5926f-d229-47c4-8a4a-e51ca15240fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dump has been saved as file ../Data/Dump/cf_knnbasic_all.dump\n"
     ]
    }
   ],
   "source": [
    "surprise.dump.dump(\n",
    "    \"../Data/Dump/cf_knnbasic_all.dump\",\n",
    "    predictions=predictions,\n",
    "    algo=algo,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773d57d5-cd10-4e7e-bac2-c45347dff12d",
   "metadata": {},
   "source": [
    "Dump files can be retrieved by `dump.load(filename)`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
